{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eecs/jahnavis/miniconda/envs/EpitomeNewEnv2/lib/python3.6/site-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "from epitome.models import *\n",
    "from epitome.functions import *\n",
    "from epitome.viz  import *\n",
    "\n",
    "from epitome.constants import *\n",
    "from epitome.motif_functions import *\n",
    "import yaml\n",
    "import subprocess\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = \"results\"\n",
    "epitome_data_path = \"data/epitome_data\" \n",
    "motif_dir = \"data/motif_data/\"\n",
    "feature_path = os.path.join(epitome_data_path, \"feature_name\")\n",
    "\n",
    "# TF's being predicted\n",
    "TF = \"EGR1\"\n",
    "query_cell = 'K562' #'T47D'\n",
    "\n",
    "train_iterations = 5000\n",
    "test_iterations = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_directories(TF, results_path=results_path):\n",
    "    # create user directories if they do not exist\n",
    "    epitome_results_dir = os.path.join(results_path, \"epitome_results\")\n",
    "    if not os.path.exists(epitome_results_dir):\n",
    "        os.makedirs(epitome_results_dir)\n",
    "\n",
    "    epitome_models_dir = os.path.join(results_path, \"epitome_models\")\n",
    "    if not os.path.exists(epitome_results_dir):\n",
    "        os.makedirs(epitome_models_dir)\n",
    "\n",
    "    # Folder based on TF being predicted\n",
    "    tf_results_dir = os.path.join(epitome_results_dir, TF + \"_results\")\n",
    "    if not os.path.exists(tf_results_dir):\n",
    "        os.makedirs(tf_results_dir)\n",
    "\n",
    "    # Folder based on TF being predicted\n",
    "    tf_model_dir = os.path.join(epitome_models_dir, TF + \"_models\")\n",
    "    if not os.path.exists(tf_model_dir):\n",
    "        os.makedirs(tf_model_dir)\n",
    "    \n",
    "    return tf_results_dir, tf_model_dir\n",
    "\n",
    "tf_results_dir, tf_model_dir = setup_directories(TF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Data for Epitome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = scipy.sparse.load_npz(os.path.join(epitome_data_path, 'train.npz')).toarray()\n",
    "valid_data = scipy.sparse.load_npz(os.path.join(epitome_data_path, 'valid.npz')).toarray()\n",
    "test_data = scipy.sparse.load_npz(os.path.join(epitome_data_path, 'test.npz')).toarray()\n",
    "data = {Dataset.TRAIN: train_data, Dataset.VALID: valid_data, Dataset.TEST: test_data}\n",
    "# all_data = np.concatenate((data[Dataset.TRAIN], data[Dataset.VALID], data[Dataset.TEST]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "motifmat = np.load(os.path.join(motif_dir, \"OVERLAP_HOCOMOCO_unique_motifmat.npz\"))[\"tf\"]\n",
    "motifmap = pd.read_csv(os.path.join(motif_dir, \"OVERLAP_HOCOMOCO_unique_motifmap.csv\"), \n",
    "                       header=None).rename(columns={0:\"Index\", 1:\"TF\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,\n",
       " 9,\n",
       " {'CTCF', 'E2F1', 'EGR1', 'FOXA1', 'GABPA', 'JUND', 'MAX', 'REST', 'TAF1'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine Anchor TF's we have data for\n",
    "epitome_tfs = list(motifmap[\"TF\"].unique()) + [\"DNase\"]\n",
    "anchor_tfs = [\"CTCF\", \"E2F1\", \"EGR1\", \"FOXA1\", \"FOXA2\", \"GABPA\", \"HNF4A\", \"JUND\", \n",
    "              \"MAX\", \"NANOG\", \"REST\", \"TAF1\"]\n",
    "anchor_overlap_tfs = set(epitome_tfs).intersection(set(anchor_tfs))\n",
    "len(anchor_tfs), len(anchor_overlap_tfs), anchor_overlap_tfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train VLP Model With Motif Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix, cellmap, assaymap = get_assays_from_feature_file(feature_path,\n",
    "                                                         eligible_assays = TF,\n",
    "                                                         eligible_cells = None, \n",
    "                                                         min_cells_per_assay = 2, \n",
    "                                                         min_assays_per_cell= 2) #10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_ind = motifmap[motifmap[\"TF\"].isin(anchor_overlap_tfs)]['Index'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 3268840)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motifmat[mat_ind, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using ['K562', 'H1', 'GM12878'] as labels for mode Dataset.TRAIN\n",
      "motif_assays:  ['EGR1']\n",
      "using ['K562', 'H1', 'GM12878'] as labels for mode Dataset.VALID\n",
      "motif_assays:  ['EGR1']\n",
      "WARNING:tensorflow:From /home/eecs/jahnavis/miniconda/envs/EpitomeNewEnv2/lib/python3.6/site-packages/tensorflow_probability/python/layers/util.py:106: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "INFO:tensorflow:Starting Training\n",
      "INFO:tensorflow:0 tf.Tensor(53.239796, shape=(), dtype=float32)tf.Tensor(45.314137, shape=(), dtype=float32)tf.Tensor(7.9256587, shape=(), dtype=float32)\n",
      "INFO:tensorflow:1000 tf.Tensor(19.375076, shape=(), dtype=float32)tf.Tensor(13.695102, shape=(), dtype=float32)tf.Tensor(5.6799746, shape=(), dtype=float32)\n",
      "INFO:tensorflow:2000 tf.Tensor(7.1557245, shape=(), dtype=float32)tf.Tensor(2.9662507, shape=(), dtype=float32)tf.Tensor(4.1894736, shape=(), dtype=float32)\n",
      "INFO:tensorflow:3000 tf.Tensor(5.252386, shape=(), dtype=float32)tf.Tensor(1.8430265, shape=(), dtype=float32)tf.Tensor(3.4093595, shape=(), dtype=float32)\n",
      "INFO:tensorflow:4000 tf.Tensor(13.413572, shape=(), dtype=float32)tf.Tensor(10.433568, shape=(), dtype=float32)tf.Tensor(2.9800043, shape=(), dtype=float32)\n",
      "epitome train time 764.298108\n"
     ]
    }
   ],
   "source": [
    "model = VLP(TF,\n",
    "            data = data,\n",
    "            matrix = matrix,\n",
    "            cellmap = cellmap,\n",
    "            assaymap = assaymap,\n",
    "            motifmat = motifmat, \n",
    "            motifmap = motifmap,\n",
    "            motif_assays = [TF])\n",
    "\n",
    "start = timer()\n",
    "model.train(train_iterations)\n",
    "end = timer()\n",
    "train_time = end-start\n",
    "print('epitome train time %f' % train_time)\n",
    "\n",
    "model_path = os.path.join(tf_model_dir, query_cell + \"_\" + TF + \"_motif\")\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:20,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:macro auROC:     0.8624020168460068\n",
      "INFO:tensorflow:auPRC:     0.27509110518020485\n",
      "INFO:tensorflow:GINI:     0.7248040753589121\n",
      "Model auROC: 0.8624020168460068. Model auPRC: 0.27509110518020485.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_results = model.test(test_iterations, calculate_metrics=True)\n",
    "print('Model auROC: %s. Model auPRC: %s.' % (model_results['auROC'], model_results['auPRC'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results_df = pd.DataFrame(columns=['query_cell', 'auROC', 'auPRC'])\n",
    "eval_results_df = eval_results_df.append({ \n",
    "   'predicted_transcription_factor' : TF, #\", \".join(anchor_overlap_tfs),\n",
    "   'query_cell' : query_cell,\n",
    "   'auROC' : model_results['auROC'],\n",
    "   'auPRC' : model_results['auPRC'],\n",
    "   'trained_transcription_factors' : TF, #\", \".join(anchor_overlap_tfs),\n",
    "   'motif_transcription_factors' : TF,\n",
    "   'iterations_trained' : train_iterations,\n",
    "   'iterations_tested' : test_iterations,\n",
    "   'train_time' : train_time,\n",
    "    }, \n",
    "    ignore_index=True)\n",
    "eval_results_df.to_csv(os.path.join(tf_results_dir, query_cell + \"_\" + TF + '_motif.csv'), \n",
    "                       sep=\"\\t\")\n",
    "\n",
    "preds_file = os.path.join(tf_results_dir, query_cell + \"_\" + TF + '_motif.npz')\n",
    "np.savez_compressed(preds_file ,pred=model_results['preds_mean'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0089899 ],\n",
       "       [0.00424215],\n",
       "       [0.00695356],\n",
       "       ...,\n",
       "       [0.00584844],\n",
       "       [0.00483397],\n",
       "       [0.09490332]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results['preds_mean'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'preds_mean': <tf.Tensor: shape=(10000, 1), dtype=float32, numpy=\n",
       " array([[0.0089899 ],\n",
       "        [0.00424215],\n",
       "        [0.00695356],\n",
       "        ...,\n",
       "        [0.00584844],\n",
       "        [0.00483397],\n",
       "        [0.09490332]], dtype=float32)>,\n",
       " 'preds_std': <tf.Tensor: shape=(10000, 1), dtype=float32, numpy=\n",
       " array([[0.00395101],\n",
       "        [0.00108542],\n",
       "        [0.00239465],\n",
       "        ...,\n",
       "        [0.00305609],\n",
       "        [0.00160502],\n",
       "        [0.04667194]], dtype=float32)>,\n",
       " 'truth': <tf.Tensor: shape=(10000, 1), dtype=float32, numpy=\n",
       " array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]], dtype=float32)>,\n",
       " 'weights': <tf.Tensor: shape=(10000, 1), dtype=float32, numpy=\n",
       " array([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        ...,\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]], dtype=float32)>,\n",
       " 'assay_dict': {'EGR1': {'AUC': 0.8624020168460068,\n",
       "   'auPRC': 0.27509110518020485,\n",
       "   'GINI': 0.7248040753589121}},\n",
       " 'auROC': 0.8624020168460068,\n",
       " 'auPRC': 0.27509110518020485}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VLP Model Without Motif Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix, cellmap, assaymap = get_assays_from_feature_file(feature_path,\n",
    "                                                         eligible_assays = TF,\n",
    "                                                         eligible_cells = None, \n",
    "                                                         min_cells_per_assay = 2, \n",
    "                                                         min_assays_per_cell= 2) #10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using ['K562', 'H1', 'GM12878'] as labels for mode Dataset.TRAIN\n",
      "motif_assays:  None\n",
      "using ['K562', 'H1', 'GM12878'] as labels for mode Dataset.VALID\n",
      "motif_assays:  None\n",
      "INFO:tensorflow:Starting Training\n",
      "INFO:tensorflow:0 tf.Tensor(51.907845, shape=(), dtype=float32)tf.Tensor(44.56864, shape=(), dtype=float32)tf.Tensor(7.339202, shape=(), dtype=float32)\n",
      "INFO:tensorflow:1000 tf.Tensor(6.508755, shape=(), dtype=float32)tf.Tensor(1.2570472, shape=(), dtype=float32)tf.Tensor(5.251708, shape=(), dtype=float32)\n",
      "INFO:tensorflow:2000 tf.Tensor(4.4476795, shape=(), dtype=float32)tf.Tensor(0.59245855, shape=(), dtype=float32)tf.Tensor(3.8552208, shape=(), dtype=float32)\n",
      "INFO:tensorflow:3000 tf.Tensor(5.541329, shape=(), dtype=float32)tf.Tensor(2.4400764, shape=(), dtype=float32)tf.Tensor(3.1012526, shape=(), dtype=float32)\n",
      "INFO:tensorflow:4000 tf.Tensor(4.443017, shape=(), dtype=float32)tf.Tensor(1.7138529, shape=(), dtype=float32)tf.Tensor(2.7291644, shape=(), dtype=float32)\n",
      "epitome train time 753.238308\n"
     ]
    }
   ],
   "source": [
    "model = VLP(TF,\n",
    "            data = data,\n",
    "            matrix = matrix,\n",
    "            cellmap = cellmap,\n",
    "            assaymap = assaymap)\n",
    "\n",
    "start = timer()\n",
    "model.train(train_iterations)\n",
    "end = timer()\n",
    "train_time = end-start\n",
    "print('epitome train time %f' % train_time)\n",
    "\n",
    "model_path = os.path.join(tf_model_dir, query_cell + \"_\" + TF + \"_no_motif\")\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:16,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:macro auROC:     0.867253058335861\n",
      "INFO:tensorflow:auPRC:     0.2984019171488106\n",
      "INFO:tensorflow:GINI:     0.7345061166717217\n",
      "Model auROC: 0.867253058335861. Model auPRC: 0.2984019171488106.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_results = model.test(test_iterations, calculate_metrics=True)\n",
    "print('Model auROC: %s. Model auPRC: %s.' % (model_results['auROC'], model_results['auPRC'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results_df = pd.DataFrame(columns=['query_cell', 'auROC', 'auPRC'])\n",
    "eval_results_df = eval_results_df.append({ \n",
    "   'predicted_transcription_factor' : TF, #\", \".join(anchor_overlap_tfs),\n",
    "   'query_cell' : query_cell,\n",
    "   'auROC' : model_results['auROC'],\n",
    "   'auPRC' : model_results['auPRC'],\n",
    "   'trained_transcription_factors' : TF, #\", \".join(anchor_overlap_tfs),\n",
    "   'iterations_trained' : train_iterations,\n",
    "   'iterations_tested' : test_iterations,\n",
    "   'train_time' : train_time,\n",
    "    }, \n",
    "    ignore_index=True)\n",
    "eval_results_df.to_csv(os.path.join(tf_results_dir, query_cell + \"_\" + TF + '_no_motif.csv'), \n",
    "                       sep=\"\\t\")\n",
    "\n",
    "preds_file = os.path.join(tf_results_dir, query_cell + \"_\" + TF + '_no_motif.npz')\n",
    "np.savez_compressed(preds_file ,pred=model_results['preds_mean'].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/ Evaluate on all Anchor TF's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training E2F1...\n",
      "using ['K562', 'HeLa-S3'] as labels for mode Dataset.TRAIN\n",
      "motif_assays:  ['E2F1']\n",
      "using ['K562', 'HeLa-S3'] as labels for mode Dataset.VALID\n",
      "motif_assays:  ['E2F1']\n",
      "INFO:tensorflow:Starting Training\n",
      "INFO:tensorflow:0 tf.Tensor(45.529, shape=(), dtype=float32)tf.Tensor(40.207222, shape=(), dtype=float32)tf.Tensor(5.3217773, shape=(), dtype=float32)\n",
      "INFO:tensorflow:1000 tf.Tensor(13.986225, shape=(), dtype=float32)tf.Tensor(10.15517, shape=(), dtype=float32)tf.Tensor(3.8310552, shape=(), dtype=float32)\n",
      "INFO:tensorflow:2000 tf.Tensor(9.72357, shape=(), dtype=float32)tf.Tensor(6.84454, shape=(), dtype=float32)tf.Tensor(2.8790293, shape=(), dtype=float32)\n",
      "INFO:tensorflow:3000 tf.Tensor(3.1363087, shape=(), dtype=float32)tf.Tensor(0.70637953, shape=(), dtype=float32)tf.Tensor(2.4299293, shape=(), dtype=float32)\n",
      "INFO:tensorflow:4000 tf.Tensor(2.8301988, shape=(), dtype=float32)tf.Tensor(0.5962671, shape=(), dtype=float32)tf.Tensor(2.2339318, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E2F1 Motif Train Time 686.147521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:18,  8.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:macro auROC:     0.8304208416833668\n",
      "INFO:tensorflow:auPRC:     0.00785415467696559\n",
      "INFO:tensorflow:GINI:     0.6608416540111473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using ['K562', 'HeLa-S3'] as labels for mode Dataset.TRAIN\n",
      "motif_assays:  None\n",
      "using ['K562', 'HeLa-S3'] as labels for mode Dataset.VALID\n",
      "motif_assays:  None\n",
      "INFO:tensorflow:Starting Training\n",
      "INFO:tensorflow:0 tf.Tensor(49.71366, shape=(), dtype=float32)tf.Tensor(44.809994, shape=(), dtype=float32)tf.Tensor(4.9036665, shape=(), dtype=float32)\n",
      "INFO:tensorflow:1000 tf.Tensor(10.140776, shape=(), dtype=float32)tf.Tensor(6.5533257, shape=(), dtype=float32)tf.Tensor(3.58745, shape=(), dtype=float32)\n",
      "INFO:tensorflow:2000 tf.Tensor(5.0243073, shape=(), dtype=float32)tf.Tensor(2.321229, shape=(), dtype=float32)tf.Tensor(2.7030783, shape=(), dtype=float32)\n",
      "INFO:tensorflow:3000 tf.Tensor(4.179045, shape=(), dtype=float32)tf.Tensor(1.8616295, shape=(), dtype=float32)tf.Tensor(2.3174157, shape=(), dtype=float32)\n",
      "INFO:tensorflow:4000 tf.Tensor(2.999199, shape=(), dtype=float32)tf.Tensor(0.88199866, shape=(), dtype=float32)tf.Tensor(2.1172004, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E2F1 Non-Motif Train Time 724.162804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:18,  8.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:macro auROC:     0.8882565130260521\n",
      "INFO:tensorflow:auPRC:     0.018985406190576593\n",
      "INFO:tensorflow:GINI:     0.7765129869113226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GABPA...\n",
      "using ['K562', 'HepG2', 'HeLa-S3', 'H1', 'GM12878', 'A549'] as labels for mode Dataset.TRAIN\n",
      "motif_assays:  ['GABPA']\n",
      "using ['K562', 'HepG2', 'HeLa-S3', 'H1', 'GM12878', 'A549'] as labels for mode Dataset.VALID\n",
      "motif_assays:  ['GABPA']\n",
      "INFO:tensorflow:Starting Training\n",
      "INFO:tensorflow:0 tf.Tensor(60.63433, shape=(), dtype=float32)tf.Tensor(44.74984, shape=(), dtype=float32)tf.Tensor(15.88449, shape=(), dtype=float32)\n",
      "INFO:tensorflow:1000 tf.Tensor(21.058237, shape=(), dtype=float32)tf.Tensor(10.257835, shape=(), dtype=float32)tf.Tensor(10.800402, shape=(), dtype=float32)\n",
      "INFO:tensorflow:2000 tf.Tensor(14.720209, shape=(), dtype=float32)tf.Tensor(7.279008, shape=(), dtype=float32)tf.Tensor(7.4412017, shape=(), dtype=float32)\n",
      "INFO:tensorflow:3000 tf.Tensor(6.2709317, shape=(), dtype=float32)tf.Tensor(0.8496717, shape=(), dtype=float32)tf.Tensor(5.42126, shape=(), dtype=float32)\n",
      "INFO:tensorflow:4000 tf.Tensor(4.6215444, shape=(), dtype=float32)tf.Tensor(0.3142025, shape=(), dtype=float32)tf.Tensor(4.307342, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GABPA Motif Train Time 1255.451235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:30,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:macro auROC:     0.8070505758637957\n",
      "INFO:tensorflow:auPRC:     0.011481077721299419\n",
      "INFO:tensorflow:GINI:     0.6141011321670005\n",
      "using ['K562', 'HepG2', 'HeLa-S3', 'H1', 'GM12878', 'A549'] as labels for mode Dataset.TRAIN\n",
      "motif_assays:  None\n",
      "using ['K562', 'HepG2', 'HeLa-S3', 'H1', 'GM12878', 'A549'] as labels for mode Dataset.VALID\n",
      "motif_assays:  None\n",
      "INFO:tensorflow:Starting Training\n",
      "INFO:tensorflow:0 tf.Tensor(62.871258, shape=(), dtype=float32)tf.Tensor(48.130913, shape=(), dtype=float32)tf.Tensor(14.740345, shape=(), dtype=float32)\n",
      "INFO:tensorflow:1000 tf.Tensor(19.880205, shape=(), dtype=float32)tf.Tensor(9.781725, shape=(), dtype=float32)tf.Tensor(10.09848, shape=(), dtype=float32)\n",
      "INFO:tensorflow:2000 tf.Tensor(13.626184, shape=(), dtype=float32)tf.Tensor(6.514467, shape=(), dtype=float32)tf.Tensor(7.111717, shape=(), dtype=float32)\n",
      "INFO:tensorflow:3000 tf.Tensor(23.139746, shape=(), dtype=float32)tf.Tensor(17.803673, shape=(), dtype=float32)tf.Tensor(5.3360734, shape=(), dtype=float32)\n",
      "INFO:tensorflow:4000 tf.Tensor(7.4464846, shape=(), dtype=float32)tf.Tensor(3.1308875, shape=(), dtype=float32)tf.Tensor(4.315597, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GABPA Non-Motif Train Time 1258.165177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:30,  5.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:macro auROC:     0.8207110665998998\n",
      "INFO:tensorflow:auPRC:     0.01918505803798979\n",
      "INFO:tensorflow:GINI:     0.6414221429800951\n"
     ]
    }
   ],
   "source": [
    "for tf in  ['E2F1', 'GABPA']:#anchor_overlap_tfs:\n",
    "    # TF's being predicted\n",
    "    TF = tf\n",
    "    \n",
    "#     if TF in [\"CTCF\", \"JUND\"]:\n",
    "#         continue\n",
    "    \n",
    "    print(\"Training %s...\" % TF)\n",
    "    query_cell = 'K562' #'T47D'\n",
    "    \n",
    "    tf_results_dir, tf_model_dir = setup_directories(TF)\n",
    "    \n",
    "    matrix, cellmap, assaymap = get_assays_from_feature_file(feature_path,\n",
    "                                                         eligible_assays = TF,\n",
    "                                                         eligible_cells = None, \n",
    "                                                         min_cells_per_assay = 2, \n",
    "                                                         min_assays_per_cell= 2)\n",
    "    \n",
    "    # Train TF with Motif Data\n",
    "    model = VLP(TF,\n",
    "            data = data,\n",
    "            matrix = matrix,\n",
    "            cellmap = cellmap,\n",
    "            assaymap = assaymap,\n",
    "            motifmat = motifmat, \n",
    "            motifmap = motifmap,\n",
    "            motif_assays = [TF])\n",
    "\n",
    "    start = timer()\n",
    "    model.train(train_iterations)\n",
    "    end = timer()\n",
    "    train_time = end-start\n",
    "    print('%s Motif Train Time %f' % (TF, train_time))\n",
    "\n",
    "    model_path = os.path.join(tf_model_dir, query_cell + \"_\" + TF + \"_motif\")\n",
    "\n",
    "    model.save(model_path)\n",
    "    \n",
    "    # Test TF with Motif Model\n",
    "    model_results = model.test(test_iterations, calculate_metrics=True)\n",
    "    \n",
    "    # Save Motif Model\n",
    "    eval_results_df = pd.DataFrame(columns=['query_cell', 'auROC', 'auPRC'])\n",
    "    eval_results_df = eval_results_df.append({ \n",
    "       'predicted_transcription_factor' : TF, #\", \".join(anchor_overlap_tfs),\n",
    "       'query_cell' : query_cell,\n",
    "       'auROC' : model_results['auROC'],\n",
    "       'auPRC' : model_results['auPRC'],\n",
    "       'trained_transcription_factors' : TF, #\", \".join(anchor_overlap_tfs),\n",
    "       'motif_transcription_factors' : TF, #\", \".join(anchor_overlap_tfs),\n",
    "       'iterations_trained' : train_iterations,\n",
    "       'iterations_tested' : test_iterations,\n",
    "       'train_time' : train_time,\n",
    "        }, \n",
    "        ignore_index=True)\n",
    "    eval_results_df.to_csv(os.path.join(tf_results_dir, query_cell + \"_\" + TF + \n",
    "                                        '_motif.csv'), sep=\"\\t\")\n",
    "\n",
    "    preds_file = os.path.join(tf_results_dir, query_cell + \"_\" + TF + '_motif.npz')\n",
    "    np.savez_compressed(preds_file ,pred=model_results['preds_mean'].numpy())\n",
    "    \n",
    "    # Train TF without Motif Data\n",
    "    model = VLP(TF,\n",
    "            data = data,\n",
    "            matrix = matrix,\n",
    "            cellmap = cellmap,\n",
    "            assaymap = assaymap)\n",
    "\n",
    "    start = timer()\n",
    "    model.train(train_iterations)\n",
    "    end = timer()\n",
    "    train_time = end-start\n",
    "    print('%s Non-Motif Train Time %f' % (TF, train_time))\n",
    "\n",
    "    model_path = os.path.join(tf_model_dir, query_cell + \"_\" + TF + \"_no_motif\")\n",
    "    model.save(model_path)\n",
    "    \n",
    "    # Test TF with Non-Motif Model\n",
    "    model_results = model.test(test_iterations, calculate_metrics=True)\n",
    "    \n",
    "    eval_results_df = pd.DataFrame(columns=['query_cell', 'auROC', 'auPRC'])\n",
    "    eval_results_df = eval_results_df.append({ \n",
    "       'predicted_transcription_factor' : TF,\n",
    "       'query_cell' : query_cell,\n",
    "       'auROC' : model_results['auROC'],\n",
    "       'auPRC' : model_results['auPRC'],\n",
    "       'trained_transcription_factors' : TF,\n",
    "       'iterations_trained' : train_iterations,\n",
    "       'iterations_tested' : test_iterations,\n",
    "       'train_time' : train_time,\n",
    "        }, \n",
    "        ignore_index=True)\n",
    "    eval_results_df.to_csv(os.path.join(tf_results_dir, query_cell + \"_\" + TF + '_no_motif.csv'), \n",
    "                           sep=\"\\t\")\n",
    "\n",
    "    preds_file = os.path.join(tf_results_dir, query_cell + \"_\" + TF + '_no_motif.npz')\n",
    "    np.savez_compressed(preds_file ,pred=model_results['preds_mean'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EpitomeNewEnv2",
   "language": "python",
   "name": "epitomenewenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
