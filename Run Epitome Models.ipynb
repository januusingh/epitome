{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eecs/jahnavis/miniconda/envs/EpitomeNewEnv2/lib/python3.6/site-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "from epitome.models import *\n",
    "from epitome.functions import *\n",
    "from epitome.viz  import *\n",
    "\n",
    "from epitome.constants import *\n",
    "from epitome.motif_functions import *\n",
    "import yaml\n",
    "import subprocess\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = \"results\"\n",
    "epitome_data_path = \"data/epitome_data\" \n",
    "motif_dir = \"data/motif_data/\"\n",
    "feature_path = os.path.join(epitome_data_path, \"feature_name\")\n",
    "\n",
    "# TF's being predicted\n",
    "TF = \"JUND\"\n",
    "query_cell = 'K562' #'T47D'\n",
    "\n",
    "train_iterations = 5000\n",
    "test_iterations = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_directories(TF, results_path=results_path):\n",
    "    # create user directories if they do not exist\n",
    "    epitome_results_dir = os.path.join(results_path, \"epitome_results\")\n",
    "    if not os.path.exists(epitome_results_dir):\n",
    "        os.makedirs(epitome_results_dir)\n",
    "\n",
    "    epitome_models_dir = os.path.join(results_path, \"epitome_models\")\n",
    "    if not os.path.exists(epitome_results_dir):\n",
    "        os.makedirs(epitome_models_dir)\n",
    "\n",
    "    # Folder based on TF being predicted\n",
    "    tf_results_dir = os.path.join(epitome_results_dir, TF + \"_results\")\n",
    "    if not os.path.exists(tf_results_dir):\n",
    "        os.makedirs(tf_results_dir)\n",
    "\n",
    "    # Folder based on TF being predicted\n",
    "    tf_model_dir = os.path.join(epitome_models_dir, TF + \"_models\")\n",
    "    if not os.path.exists(tf_model_dir):\n",
    "        os.makedirs(tf_model_dir)\n",
    "    \n",
    "    return tf_results_dir, tf_model_dir\n",
    "\n",
    "tf_results_dir, tf_model_dir = setup_directories(TF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Data for Epitome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = scipy.sparse.load_npz(os.path.join(epitome_data_path, 'train.npz')).toarray()\n",
    "valid_data = scipy.sparse.load_npz(os.path.join(epitome_data_path, 'valid.npz')).toarray()\n",
    "test_data = scipy.sparse.load_npz(os.path.join(epitome_data_path, 'test.npz')).toarray()\n",
    "data = {Dataset.TRAIN: train_data, Dataset.VALID: valid_data, Dataset.TEST: test_data}\n",
    "# all_data = np.concatenate((data[Dataset.TRAIN], data[Dataset.VALID], data[Dataset.TEST]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "motifmat = np.load(os.path.join(motif_dir, \"OVERLAP_HOCOMOCO_unique_motifmat.npz\"))[\"tf\"]\n",
    "motifmap = pd.read_csv(os.path.join(motif_dir, \"OVERLAP_HOCOMOCO_unique_motifmap.csv\"), \n",
    "                       header=None).rename(columns={0:\"Index\", 1:\"TF\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,\n",
       " 9,\n",
       " {'CTCF', 'E2F1', 'EGR1', 'FOXA1', 'GABPA', 'JUND', 'MAX', 'REST', 'TAF1'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine Anchor TF's we have data for\n",
    "epitome_tfs = list(motifmap[\"TF\"].unique()) + [\"DNase\"]\n",
    "anchor_tfs = [\"CTCF\", \"E2F1\", \"EGR1\", \"FOXA1\", \"FOXA2\", \"GABPA\", \"HNF4A\", \"JUND\", \n",
    "              \"MAX\", \"NANOG\", \"REST\", \"TAF1\"]\n",
    "anchor_overlap_tfs = set(epitome_tfs).intersection(set(anchor_tfs))\n",
    "len(anchor_tfs), len(anchor_overlap_tfs), anchor_overlap_tfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train VLP Model With Motif Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix, cellmap, assaymap = get_assays_from_feature_file(feature_path,\n",
    "                                                         eligible_assays = TF,\n",
    "                                                         eligible_cells = None, \n",
    "                                                         min_cells_per_assay = 2, \n",
    "                                                         min_assays_per_cell= 2) #10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using ['T47D', 'SK-N-SH', 'MCF-7', 'K562', 'HepG2', 'HeLa-S3', 'HCT116', 'H1', 'GM12878', 'A549'] as labels for mode Dataset.TRAIN\n",
      "using ['T47D', 'SK-N-SH', 'MCF-7', 'K562', 'HepG2', 'HeLa-S3', 'HCT116', 'H1', 'GM12878', 'A549'] as labels for mode Dataset.VALID\n",
      "INFO:tensorflow:Starting Training\n",
      "INFO:tensorflow:0 tf.Tensor(71.51683, shape=(), dtype=float32)tf.Tensor(32.367836, shape=(), dtype=float32)tf.Tensor(39.148994, shape=(), dtype=float32)\n",
      "INFO:tensorflow:1000 tf.Tensor(43.75319, shape=(), dtype=float32)tf.Tensor(17.765388, shape=(), dtype=float32)tf.Tensor(25.9878, shape=(), dtype=float32)\n",
      "INFO:tensorflow:2000 tf.Tensor(27.510347, shape=(), dtype=float32)tf.Tensor(10.572031, shape=(), dtype=float32)tf.Tensor(16.938316, shape=(), dtype=float32)\n",
      "INFO:tensorflow:3000 tf.Tensor(27.68876, shape=(), dtype=float32)tf.Tensor(15.903814, shape=(), dtype=float32)tf.Tensor(11.7849455, shape=(), dtype=float32)\n",
      "INFO:tensorflow:4000 tf.Tensor(24.891537, shape=(), dtype=float32)tf.Tensor(15.913477, shape=(), dtype=float32)tf.Tensor(8.97806, shape=(), dtype=float32)\n",
      "epitome train time 1691.131049\n"
     ]
    }
   ],
   "source": [
    "model = VLP(TF,\n",
    "            data = data,\n",
    "            matrix = matrix,\n",
    "            cellmap = cellmap,\n",
    "            assaymap = assaymap,\n",
    "            motifmat = motifmat, \n",
    "            motifmap = motifmap)\n",
    "\n",
    "start = timer()\n",
    "model.train(train_iterations)\n",
    "end = timer()\n",
    "train_time = end-start\n",
    "print('epitome train time %f' % train_time)\n",
    "\n",
    "model_path = os.path.join(tf_model_dir, query_cell + \"_\" + TF + \"_motif\")\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:39,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:macro auROC:     0.9084975686826244\n",
      "INFO:tensorflow:auPRC:     0.02531934997275975\n",
      "INFO:tensorflow:GINI:     0.5623797544778633\n",
      "Model auROC: 0.9084975686826244. Model auPRC: 0.02531934997275975.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_results = model.test(test_iterations, calculate_metrics=True)\n",
    "print('Model auROC: %s. Model auPRC: %s.' % (model_results['auROC'], model_results['auPRC'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results_df = pd.DataFrame(columns=['query_cell', 'auROC', 'auPRC'])\n",
    "eval_results_df = eval_results_df.append({ \n",
    "   'predicted_transcription_factor' : TF, #\", \".join(anchor_overlap_tfs),\n",
    "   'query_cell' : query_cell,\n",
    "   'auROC' : model_results['auROC'],\n",
    "   'auPRC' : model_results['auPRC'],\n",
    "   'trained_transcription_factors' : TF, #\", \".join(anchor_overlap_tfs),\n",
    "   'iterations_trained' : train_iterations,\n",
    "   'iterations_tested' : test_iterations,\n",
    "   'train_time' : train_time,\n",
    "    }, \n",
    "    ignore_index=True)\n",
    "eval_results_df.to_csv(os.path.join(tf_results_dir, query_cell + \"_\" + TF + '_motif.csv'), \n",
    "                       sep=\"\\t\")\n",
    "\n",
    "preds_file = os.path.join(tf_results_dir, query_cell + \"_\" + TF + '_motif.npz')\n",
    "np.savez_compressed(preds_file ,pred=model_results['preds_mean'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03256017, 0.02350445],\n",
       "       [0.12821168, 0.04365126],\n",
       "       [0.064019  , 0.03120099],\n",
       "       ...,\n",
       "       [0.07639625, 0.03591267],\n",
       "       [0.01666835, 0.0120222 ],\n",
       "       [0.01700682, 0.00828141]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results['preds_mean'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'preds_mean': <tf.Tensor: shape=(10000, 2), dtype=float32, numpy=\n",
       " array([[0.03256017, 0.02350445],\n",
       "        [0.12821168, 0.04365126],\n",
       "        [0.064019  , 0.03120099],\n",
       "        ...,\n",
       "        [0.07639625, 0.03591267],\n",
       "        [0.01666835, 0.0120222 ],\n",
       "        [0.01700682, 0.00828141]], dtype=float32)>,\n",
       " 'preds_std': <tf.Tensor: shape=(10000, 2), dtype=float32, numpy=\n",
       " array([[0.02154262, 0.01981107],\n",
       "        [0.05854309, 0.02100998],\n",
       "        [0.04072119, 0.02334389],\n",
       "        ...,\n",
       "        [0.03715775, 0.02083966],\n",
       "        [0.01057944, 0.00872744],\n",
       "        [0.0090576 , 0.00503344]], dtype=float32)>,\n",
       " 'truth': <tf.Tensor: shape=(10000, 2), dtype=float32, numpy=\n",
       " array([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        ...,\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]], dtype=float32)>,\n",
       " 'weights': <tf.Tensor: shape=(10000, 2), dtype=float32, numpy=\n",
       " array([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        ...,\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.]], dtype=float32)>,\n",
       " 'assay_dict': {'JUND': {'AUC': 0.8204957207958208,\n",
       "   'auPRC': 0.005184154490974044,\n",
       "   'GINI': 0.6222251700661072},\n",
       "  'JUN': {'AUC': 0.9964994165694282,\n",
       "   'auPRC': 0.045454545454545456,\n",
       "   'GINI': 0.5025343388896193}},\n",
       " 'auROC': 0.9084975686826244,\n",
       " 'auPRC': 0.02531934997275975}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VLP Model Without Motif Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix, cellmap, assaymap = get_assays_from_feature_file(feature_path,\n",
    "                                                         eligible_assays = TF,\n",
    "                                                         eligible_cells = None, \n",
    "                                                         min_cells_per_assay = 2, \n",
    "                                                         min_assays_per_cell= 2) #10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using ['T47D', 'SK-N-SH', 'MCF-7', 'K562', 'HepG2', 'HeLa-S3', 'HCT116', 'H1', 'GM12878', 'A549'] as labels for mode Dataset.TRAIN\n",
      "using ['T47D', 'SK-N-SH', 'MCF-7', 'K562', 'HepG2', 'HeLa-S3', 'HCT116', 'H1', 'GM12878', 'A549'] as labels for mode Dataset.VALID\n",
      "INFO:tensorflow:Starting Training\n",
      "INFO:tensorflow:0 tf.Tensor(59.26118, shape=(), dtype=float32)tf.Tensor(33.030785, shape=(), dtype=float32)tf.Tensor(26.230398, shape=(), dtype=float32)\n",
      "INFO:tensorflow:1000 tf.Tensor(42.590797, shape=(), dtype=float32)tf.Tensor(25.06586, shape=(), dtype=float32)tf.Tensor(17.524937, shape=(), dtype=float32)\n",
      "INFO:tensorflow:2000 tf.Tensor(34.080284, shape=(), dtype=float32)tf.Tensor(22.320139, shape=(), dtype=float32)tf.Tensor(11.760146, shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-b74f0bec2817>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtrain_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/epitome_new/epitome-1/epitome/models.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_steps, lr, checkpoint_path)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/EpitomeNewEnv2/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mRUN_FUNCTIONS_EAGERLY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/epitome_new/epitome-1/epitome/models.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m                 \u001b[0mkl_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0mneg_log_likelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/EpitomeNewEnv2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/EpitomeNewEnv2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    715\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    716\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/EpitomeNewEnv2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/EpitomeNewEnv2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    821\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/EpitomeNewEnv2/lib/python3.6/site-packages/tensorflow_probability/python/layers/dense_variational.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_variational_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_variational_bias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/EpitomeNewEnv2/lib/python3.6/site-packages/tensorflow_probability/python/layers/dense_variational.py\u001b[0m in \u001b[0;36m_apply_variational_kernel\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    679\u001b[0m     self.kernel_posterior_affine = normal_lib.Normal(\n\u001b[1;32m    680\u001b[0m         \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_posterior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m         scale=self.kernel_posterior.distribution.scale)\n\u001b[0m\u001b[1;32m    682\u001b[0m     self.kernel_posterior_affine_tensor = (\n\u001b[1;32m    683\u001b[0m         self.kernel_posterior_tensor_fn(self.kernel_posterior_affine))\n",
      "\u001b[0;32m<decorator-gen-239>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loc, scale, validate_args, allow_nan_stats, name)\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/EpitomeNewEnv2/lib/python3.6/site-packages/tensorflow_probability/python/distributions/distribution.py\u001b[0m in \u001b[0;36mwrapped_init\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    282\u001b[0m       \u001b[0;31m# called, here is the place to do it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m       \u001b[0mself_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m       \u001b[0mdefault_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m       \u001b[0;31m# Note: if we ever want to override things set in `self` by subclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m       \u001b[0;31m# `__init__`, here is the place to do it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/EpitomeNewEnv2/lib/python3.6/site-packages/tensorflow_probability/python/distributions/normal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loc, scale, validate_args, allow_nan_stats, name)\u001b[0m\n\u001b[1;32m    145\u001b[0m           \u001b[0mallow_nan_stats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_nan_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m           \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/EpitomeNewEnv2/lib/python3.6/site-packages/tensorflow_probability/python/distributions/distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dtype, reparameterization_type, validate_args, allow_nan_stats, parameters, graph_parents, name)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_parents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_parents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m     self._initial_parameter_control_dependencies = tuple(\n\u001b[0;32m--> 503\u001b[0;31m         \u001b[0md\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameter_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m         if d is not None)\n\u001b[1;32m    505\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_parameter_control_dependencies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/EpitomeNewEnv2/lib/python3.6/site-packages/tensorflow_probability/python/distributions/normal.py\u001b[0m in \u001b[0;36m_parameter_control_dependencies\u001b[0;34m(self, is_init)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_init\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m~/miniconda/envs/EpitomeNewEnv2/lib/python3.6/site-packages/tensorflow_probability/python/distributions/normal.py\u001b[0m in \u001b[0;36m_batch_shape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_batch_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_static_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_event_shape_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/EpitomeNewEnv2/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mbroadcast_static_shape\u001b[0;34m(shape_x, shape_y)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtwo\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0mcan\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mbroadcasted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m   \"\"\"\n\u001b[0;32m--> 480\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mcommon_shapes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/EpitomeNewEnv2/lib/python3.6/site-packages/tensorflow_core/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mbroadcast_shape\u001b[0;34m(shape_x, shape_y)\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mshape_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munknown_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m   \u001b[0mreturn_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_broadcast_shape_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreturn_dims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     raise ValueError(\"Incompatible shapes for broadcasting: %s and %s\"\n",
      "\u001b[0;32m~/miniconda/envs/EpitomeNewEnv2/lib/python3.6/site-packages/tensorflow_core/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_broadcast_shape_helper\u001b[0;34m(shape_x, shape_y)\u001b[0m\n\u001b[1;32m     39\u001b[0m       \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m       \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m       fillvalue=tensor_shape.Dimension(1))))\n\u001b[0m\u001b[1;32m     42\u001b[0m   \u001b[0;31m# Next we combine the dimensions according to the numpy broadcasting rules.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0;31m# http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = VLP(TF,\n",
    "            data = data,\n",
    "            matrix = matrix,\n",
    "            cellmap = cellmap,\n",
    "            assaymap = assaymap)\n",
    "\n",
    "start = timer()\n",
    "model.train(train_iterations)\n",
    "end = timer()\n",
    "train_time = end-start\n",
    "print('epitome train time %f' % train_time)\n",
    "\n",
    "model_path = os.path.join(tf_model_dir, query_cell + \"_\" + TF + \"_no_motif\")\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = model.test(test_iterations, calculate_metrics=True)\n",
    "print('Model auROC: %s. Model auPRC: %s.' % (model_results['auROC'], model_results['auPRC'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results_df = pd.DataFrame(columns=['query_cell', 'auROC', 'auPRC'])\n",
    "eval_results_df = eval_results_df.append({ \n",
    "   'predicted_transcription_factor' : TF, #\", \".join(anchor_overlap_tfs),\n",
    "   'query_cell' : query_cell,\n",
    "   'auROC' : model_results['auROC'],\n",
    "   'auPRC' : model_results['auPRC'],\n",
    "   'trained_transcription_factors' : TF, #\", \".join(anchor_overlap_tfs),\n",
    "   'iterations_trained' : train_iterations,\n",
    "   'iterations_tested' : test_iterations,\n",
    "   'train_time' : train_time,\n",
    "    }, \n",
    "    ignore_index=True)\n",
    "eval_results_df.to_csv(os.path.join(tf_results_dir, query_cell + \"_\" + TF + '_no_motif.csv'), \n",
    "                       sep=\"\\t\")\n",
    "\n",
    "preds_file = os.path.join(tf_results_dir, query_cell + \"_\" + TF + '_no_motif.npz')\n",
    "np.savez_compressed(preds_file ,pred=model_results['preds_mean'].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/ Evaluate on all Anchor TF's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training JUND...\n",
      "using ['T47D', 'SK-N-SH', 'MCF-7', 'K562', 'HepG2', 'HeLa-S3', 'HCT116', 'H1', 'GM12878', 'A549'] as labels for mode Dataset.TRAIN\n",
      "using ['T47D', 'SK-N-SH', 'MCF-7', 'K562', 'HepG2', 'HeLa-S3', 'HCT116', 'H1', 'GM12878', 'A549'] as labels for mode Dataset.VALID\n",
      "INFO:tensorflow:Starting Training\n",
      "INFO:tensorflow:0 tf.Tensor(67.876144, shape=(), dtype=float32)tf.Tensor(28.68024, shape=(), dtype=float32)tf.Tensor(39.195908, shape=(), dtype=float32)\n",
      "INFO:tensorflow:1000 tf.Tensor(39.79464, shape=(), dtype=float32)tf.Tensor(13.760158, shape=(), dtype=float32)tf.Tensor(26.034485, shape=(), dtype=float32)\n",
      "INFO:tensorflow:2000 tf.Tensor(34.20086, shape=(), dtype=float32)tf.Tensor(17.108875, shape=(), dtype=float32)tf.Tensor(17.091986, shape=(), dtype=float32)\n",
      "INFO:tensorflow:3000 tf.Tensor(32.006634, shape=(), dtype=float32)tf.Tensor(19.966705, shape=(), dtype=float32)tf.Tensor(12.039928, shape=(), dtype=float32)\n",
      "INFO:tensorflow:4000 tf.Tensor(25.870155, shape=(), dtype=float32)tf.Tensor(16.568203, shape=(), dtype=float32)tf.Tensor(9.301952, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JUND Motif Train Time 1687.140229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:40,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:macro auROC:     0.9284678551855514\n",
      "INFO:tensorflow:auPRC:     0.012592098172470794\n",
      "INFO:tensorflow:GINI:     0.7503683369564035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using ['T47D', 'SK-N-SH', 'MCF-7', 'K562', 'HepG2', 'HeLa-S3', 'HCT116', 'H1', 'GM12878', 'A549'] as labels for mode Dataset.TRAIN\n",
      "using ['T47D', 'SK-N-SH', 'MCF-7', 'K562', 'HepG2', 'HeLa-S3', 'HCT116', 'H1', 'GM12878', 'A549'] as labels for mode Dataset.VALID\n",
      "INFO:tensorflow:Starting Training\n",
      "INFO:tensorflow:0 tf.Tensor(57.69705, shape=(), dtype=float32)tf.Tensor(31.45293, shape=(), dtype=float32)tf.Tensor(26.24412, shape=(), dtype=float32)\n",
      "INFO:tensorflow:1000 tf.Tensor(35.459976, shape=(), dtype=float32)tf.Tensor(17.961977, shape=(), dtype=float32)tf.Tensor(17.498, shape=(), dtype=float32)\n",
      "INFO:tensorflow:2000 tf.Tensor(32.189484, shape=(), dtype=float32)tf.Tensor(20.608858, shape=(), dtype=float32)tf.Tensor(11.580624, shape=(), dtype=float32)\n",
      "INFO:tensorflow:3000 tf.Tensor(33.249386, shape=(), dtype=float32)tf.Tensor(24.942856, shape=(), dtype=float32)tf.Tensor(8.306529, shape=(), dtype=float32)\n",
      "INFO:tensorflow:4000 tf.Tensor(25.370712, shape=(), dtype=float32)tf.Tensor(18.799538, shape=(), dtype=float32)tf.Tensor(6.5711756, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JUND Non-Motif Train Time 1690.779980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:40,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:macro auROC:     0.8755799805444708\n",
      "INFO:tensorflow:auPRC:     0.008243270584466236\n",
      "INFO:tensorflow:GINI:     0.5701085785925561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training TAF1...\n",
      "using ['SK-N-SH', 'K562', 'HepG2', 'HeLa-S3', 'H1', 'GM12892', 'GM12891', 'GM12878', 'A549'] as labels for mode Dataset.TRAIN\n",
      "using ['SK-N-SH', 'K562', 'HepG2', 'HeLa-S3', 'H1', 'GM12892', 'GM12891', 'GM12878', 'A549'] as labels for mode Dataset.VALID\n",
      "INFO:tensorflow:Starting Training\n",
      "INFO:tensorflow:0 tf.Tensor(68.0641, shape=(), dtype=float32)tf.Tensor(44.188812, shape=(), dtype=float32)tf.Tensor(23.875292, shape=(), dtype=float32)\n",
      "INFO:tensorflow:1000 tf.Tensor(33.54499, shape=(), dtype=float32)tf.Tensor(17.74875, shape=(), dtype=float32)tf.Tensor(15.796238, shape=(), dtype=float32)\n",
      "INFO:tensorflow:2000 tf.Tensor(11.015478, shape=(), dtype=float32)tf.Tensor(0.55997014, shape=(), dtype=float32)tf.Tensor(10.455508, shape=(), dtype=float32)\n",
      "INFO:tensorflow:3000 tf.Tensor(7.5051203, shape=(), dtype=float32)tf.Tensor(0.36048096, shape=(), dtype=float32)tf.Tensor(7.1446395, shape=(), dtype=float32)\n",
      "INFO:tensorflow:4000 tf.Tensor(6.2515893, shape=(), dtype=float32)tf.Tensor(0.8304409, shape=(), dtype=float32)tf.Tensor(5.4211483, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAF1 Motif Train Time 1635.290672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:38,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:macro auROC:     0.9861794511884747\n",
      "INFO:tensorflow:auPRC:     0.5499812401502298\n",
      "INFO:tensorflow:GINI:     0.9723588948453479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using ['SK-N-SH', 'K562', 'HepG2', 'HeLa-S3', 'H1', 'GM12892', 'GM12891', 'GM12878', 'A549'] as labels for mode Dataset.TRAIN\n",
      "using ['SK-N-SH', 'K562', 'HepG2', 'HeLa-S3', 'H1', 'GM12892', 'GM12891', 'GM12878', 'A549'] as labels for mode Dataset.VALID\n",
      "INFO:tensorflow:Starting Training\n",
      "INFO:tensorflow:0 tf.Tensor(65.98341, shape=(), dtype=float32)tf.Tensor(43.88282, shape=(), dtype=float32)tf.Tensor(22.100597, shape=(), dtype=float32)\n",
      "INFO:tensorflow:1000 tf.Tensor(15.364998, shape=(), dtype=float32)tf.Tensor(0.7100724, shape=(), dtype=float32)tf.Tensor(14.654925, shape=(), dtype=float32)\n",
      "INFO:tensorflow:2000 tf.Tensor(10.499827, shape=(), dtype=float32)tf.Tensor(0.8507942, shape=(), dtype=float32)tf.Tensor(9.649034, shape=(), dtype=float32)\n",
      "INFO:tensorflow:3000 tf.Tensor(6.849214, shape=(), dtype=float32)tf.Tensor(0.28513256, shape=(), dtype=float32)tf.Tensor(6.5640817, shape=(), dtype=float32)\n",
      "INFO:tensorflow:4000 tf.Tensor(21.0724, shape=(), dtype=float32)tf.Tensor(16.057003, shape=(), dtype=float32)tf.Tensor(5.0153956, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAF1 Non-Motif Train Time 1624.671781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:39,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:macro auROC:     0.989302956918758\n",
      "INFO:tensorflow:auPRC:     0.5992221783919084\n",
      "INFO:tensorflow:GINI:     0.9786058987743133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training E2F1...\n",
      "using ['K562', 'HeLa-S3'] as labels for mode Dataset.TRAIN\n",
      "using ['K562', 'HeLa-S3'] as labels for mode Dataset.VALID\n",
      "INFO:tensorflow:Starting Training\n",
      "INFO:tensorflow:0 tf.Tensor(44.86111, shape=(), dtype=float32)tf.Tensor(39.538765, shape=(), dtype=float32)tf.Tensor(5.322346, shape=(), dtype=float32)\n",
      "INFO:tensorflow:1000 tf.Tensor(13.230371, shape=(), dtype=float32)tf.Tensor(9.392074, shape=(), dtype=float32)tf.Tensor(3.838298, shape=(), dtype=float32)\n",
      "INFO:tensorflow:2000 tf.Tensor(4.413699, shape=(), dtype=float32)tf.Tensor(1.5463245, shape=(), dtype=float32)tf.Tensor(2.8673744, shape=(), dtype=float32)\n",
      "INFO:tensorflow:3000 tf.Tensor(7.744392, shape=(), dtype=float32)tf.Tensor(5.3292136, shape=(), dtype=float32)tf.Tensor(2.4151783, shape=(), dtype=float32)\n",
      "INFO:tensorflow:4000 tf.Tensor(3.4688468, shape=(), dtype=float32)tf.Tensor(1.2941073, shape=(), dtype=float32)tf.Tensor(2.1747394, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E2F1 Motif Train Time 688.988659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:18,  8.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:macro auROC:     0.855065130260521\n",
      "INFO:tensorflow:auPRC:     0.008199452897898531\n",
      "INFO:tensorflow:GINI:     0.7101302213802605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using ['K562', 'HeLa-S3'] as labels for mode Dataset.TRAIN\n",
      "using ['K562', 'HeLa-S3'] as labels for mode Dataset.VALID\n",
      "INFO:tensorflow:Starting Training\n",
      "INFO:tensorflow:0 tf.Tensor(45.836567, shape=(), dtype=float32)tf.Tensor(40.940758, shape=(), dtype=float32)tf.Tensor(4.895809, shape=(), dtype=float32)\n",
      "INFO:tensorflow:1000 tf.Tensor(14.435993, shape=(), dtype=float32)tf.Tensor(10.822944, shape=(), dtype=float32)tf.Tensor(3.6130495, shape=(), dtype=float32)\n",
      "INFO:tensorflow:2000 tf.Tensor(4.0258665, shape=(), dtype=float32)tf.Tensor(1.2343924, shape=(), dtype=float32)tf.Tensor(2.7914739, shape=(), dtype=float32)\n",
      "INFO:tensorflow:3000 tf.Tensor(4.4870615, shape=(), dtype=float32)tf.Tensor(2.1164548, shape=(), dtype=float32)tf.Tensor(2.3706064, shape=(), dtype=float32)\n",
      "INFO:tensorflow:4000 tf.Tensor(5.741802, shape=(), dtype=float32)tf.Tensor(3.6087534, shape=(), dtype=float32)tf.Tensor(2.1330488, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E2F1 Non-Motif Train Time 694.783370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:17,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:macro auROC:     0.838056112224449\n",
      "INFO:tensorflow:auPRC:     0.009855910209045296\n",
      "INFO:tensorflow:GINI:     0.6761121853081162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GABPA...\n",
      "using ['K562', 'HepG2', 'HeLa-S3', 'H1', 'GM12878', 'A549'] as labels for mode Dataset.TRAIN\n",
      "using ['K562', 'HepG2', 'HeLa-S3', 'H1', 'GM12878', 'A549'] as labels for mode Dataset.VALID\n",
      "INFO:tensorflow:Starting Training\n",
      "INFO:tensorflow:0 tf.Tensor(60.636604, shape=(), dtype=float32)tf.Tensor(44.75963, shape=(), dtype=float32)tf.Tensor(15.876978, shape=(), dtype=float32)\n",
      "INFO:tensorflow:1000 tf.Tensor(11.765964, shape=(), dtype=float32)tf.Tensor(0.9757925, shape=(), dtype=float32)tf.Tensor(10.790171, shape=(), dtype=float32)\n",
      "INFO:tensorflow:2000 tf.Tensor(11.732292, shape=(), dtype=float32)tf.Tensor(4.286315, shape=(), dtype=float32)tf.Tensor(7.445977, shape=(), dtype=float32)\n",
      "INFO:tensorflow:3000 tf.Tensor(27.555895, shape=(), dtype=float32)tf.Tensor(22.123789, shape=(), dtype=float32)tf.Tensor(5.4321055, shape=(), dtype=float32)\n",
      "INFO:tensorflow:4000 tf.Tensor(4.5864677, shape=(), dtype=float32)tf.Tensor(0.3036614, shape=(), dtype=float32)tf.Tensor(4.2828064, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GABPA Motif Train Time 1229.998796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:30,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:macro auROC:     0.8138274077783342\n",
      "INFO:tensorflow:auPRC:     0.018779216425572485\n",
      "INFO:tensorflow:GINI:     0.627654861198047\n",
      "using ['K562', 'HepG2', 'HeLa-S3', 'H1', 'GM12878', 'A549'] as labels for mode Dataset.TRAIN\n",
      "using ['K562', 'HepG2', 'HeLa-S3', 'H1', 'GM12878', 'A549'] as labels for mode Dataset.VALID\n",
      "INFO:tensorflow:Starting Training\n",
      "INFO:tensorflow:0 tf.Tensor(60.26727, shape=(), dtype=float32)tf.Tensor(45.584015, shape=(), dtype=float32)tf.Tensor(14.683255, shape=(), dtype=float32)\n",
      "INFO:tensorflow:1000 tf.Tensor(10.760666, shape=(), dtype=float32)tf.Tensor(0.6522289, shape=(), dtype=float32)tf.Tensor(10.108437, shape=(), dtype=float32)\n",
      "INFO:tensorflow:2000 tf.Tensor(7.823071, shape=(), dtype=float32)tf.Tensor(0.70869935, shape=(), dtype=float32)tf.Tensor(7.114372, shape=(), dtype=float32)\n",
      "INFO:tensorflow:3000 tf.Tensor(29.458742, shape=(), dtype=float32)tf.Tensor(24.148067, shape=(), dtype=float32)tf.Tensor(5.310674, shape=(), dtype=float32)\n",
      "INFO:tensorflow:4000 tf.Tensor(12.002388, shape=(), dtype=float32)tf.Tensor(7.7051105, shape=(), dtype=float32)tf.Tensor(4.297277, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GABPA Non-Motif Train Time 1242.608600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:29,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:macro auROC:     0.8204707060590887\n",
      "INFO:tensorflow:auPRC:     0.0214142408314604\n",
      "INFO:tensorflow:GINI:     0.6409414414590636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training FOXA1...\n",
      "using ['T47D', 'MCF-7', 'K562', 'Ishikawa', 'HepG2', 'HEK293T', 'A549'] as labels for mode Dataset.TRAIN\n",
      "using ['T47D', 'MCF-7', 'K562', 'Ishikawa', 'HepG2', 'HEK293T', 'A549'] as labels for mode Dataset.VALID\n",
      "INFO:tensorflow:Starting Training\n",
      "INFO:tensorflow:0 tf.Tensor(65.80141, shape=(), dtype=float32)tf.Tensor(47.278755, shape=(), dtype=float32)tf.Tensor(18.522655, shape=(), dtype=float32)\n",
      "INFO:tensorflow:1000 tf.Tensor(17.53945, shape=(), dtype=float32)tf.Tensor(5.440012, shape=(), dtype=float32)tf.Tensor(12.099438, shape=(), dtype=float32)\n",
      "INFO:tensorflow:2000 tf.Tensor(14.157874, shape=(), dtype=float32)tf.Tensor(6.7226853, shape=(), dtype=float32)tf.Tensor(7.435189, shape=(), dtype=float32)\n",
      "INFO:tensorflow:3000 tf.Tensor(23.129192, shape=(), dtype=float32)tf.Tensor(18.011246, shape=(), dtype=float32)tf.Tensor(5.1179457, shape=(), dtype=float32)\n",
      "INFO:tensorflow:4000 tf.Tensor(22.354486, shape=(), dtype=float32)tf.Tensor(18.340899, shape=(), dtype=float32)tf.Tensor(4.0135875, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOXA1 Motif Train Time 1373.143633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:33,  4.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:macro auROC:     0.7872826433402982\n",
      "INFO:tensorflow:auPRC:     0.10814941758198923\n",
      "INFO:tensorflow:GINI:     0.574565289562638\n",
      "using ['T47D', 'MCF-7', 'K562', 'Ishikawa', 'HepG2', 'HEK293T', 'A549'] as labels for mode Dataset.TRAIN\n",
      "using ['T47D', 'MCF-7', 'K562', 'Ishikawa', 'HepG2', 'HEK293T', 'A549'] as labels for mode Dataset.VALID\n",
      "INFO:tensorflow:Starting Training\n",
      "INFO:tensorflow:0 tf.Tensor(59.749985, shape=(), dtype=float32)tf.Tensor(42.55362, shape=(), dtype=float32)tf.Tensor(17.196365, shape=(), dtype=float32)\n",
      "INFO:tensorflow:1000 tf.Tensor(16.04166, shape=(), dtype=float32)tf.Tensor(4.834282, shape=(), dtype=float32)tf.Tensor(11.207379, shape=(), dtype=float32)\n",
      "INFO:tensorflow:2000 tf.Tensor(19.55907, shape=(), dtype=float32)tf.Tensor(12.650824, shape=(), dtype=float32)tf.Tensor(6.908246, shape=(), dtype=float32)\n",
      "INFO:tensorflow:3000 tf.Tensor(11.73516, shape=(), dtype=float32)tf.Tensor(6.942775, shape=(), dtype=float32)tf.Tensor(4.792385, shape=(), dtype=float32)\n",
      "INFO:tensorflow:4000 tf.Tensor(4.8414044, shape=(), dtype=float32)tf.Tensor(1.0440967, shape=(), dtype=float32)tf.Tensor(3.7973077, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOXA1 Non-Motif Train Time 1378.620798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:32,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:macro auROC:     0.7866097673265573\n",
      "INFO:tensorflow:auPRC:     0.11313550948607104\n",
      "INFO:tensorflow:GINI:     0.5732195519453642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training REST...\n",
      "using ['SK-N-SH', 'K562', 'HepG2', 'HeLa-S3', 'H1', 'GM12878', 'A549'] as labels for mode Dataset.TRAIN\n",
      "using ['SK-N-SH', 'K562', 'HepG2', 'HeLa-S3', 'H1', 'GM12878', 'A549'] as labels for mode Dataset.VALID\n",
      "INFO:tensorflow:Starting Training\n",
      "INFO:tensorflow:0 tf.Tensor(68.20203, shape=(), dtype=float32)tf.Tensor(49.606087, shape=(), dtype=float32)tf.Tensor(18.595943, shape=(), dtype=float32)\n",
      "INFO:tensorflow:1000 tf.Tensor(13.574488, shape=(), dtype=float32)tf.Tensor(1.060781, shape=(), dtype=float32)tf.Tensor(12.513706, shape=(), dtype=float32)\n",
      "INFO:tensorflow:2000 tf.Tensor(20.345335, shape=(), dtype=float32)tf.Tensor(11.98852, shape=(), dtype=float32)tf.Tensor(8.356815, shape=(), dtype=float32)\n",
      "INFO:tensorflow:3000 tf.Tensor(21.086687, shape=(), dtype=float32)tf.Tensor(15.026542, shape=(), dtype=float32)tf.Tensor(6.0601454, shape=(), dtype=float32)\n",
      "INFO:tensorflow:4000 tf.Tensor(33.946106, shape=(), dtype=float32)tf.Tensor(29.082403, shape=(), dtype=float32)tf.Tensor(4.8637037, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REST Motif Train Time 1371.555836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:32,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:macro auROC:     0.7971319695146409\n",
      "INFO:tensorflow:auPRC:     0.05331553258418627\n",
      "INFO:tensorflow:GINI:     0.5942638900640543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using ['SK-N-SH', 'K562', 'HepG2', 'HeLa-S3', 'H1', 'GM12878', 'A549'] as labels for mode Dataset.TRAIN\n",
      "using ['SK-N-SH', 'K562', 'HepG2', 'HeLa-S3', 'H1', 'GM12878', 'A549'] as labels for mode Dataset.VALID\n",
      "INFO:tensorflow:Starting Training\n",
      "INFO:tensorflow:0 tf.Tensor(66.57971, shape=(), dtype=float32)tf.Tensor(49.43197, shape=(), dtype=float32)tf.Tensor(17.147745, shape=(), dtype=float32)\n",
      "INFO:tensorflow:1000 tf.Tensor(13.869762, shape=(), dtype=float32)tf.Tensor(2.3822074, shape=(), dtype=float32)tf.Tensor(11.4875555, shape=(), dtype=float32)\n",
      "INFO:tensorflow:2000 tf.Tensor(8.842641, shape=(), dtype=float32)tf.Tensor(1.098128, shape=(), dtype=float32)tf.Tensor(7.744513, shape=(), dtype=float32)\n",
      "INFO:tensorflow:3000 tf.Tensor(6.6615205, shape=(), dtype=float32)tf.Tensor(0.91025835, shape=(), dtype=float32)tf.Tensor(5.751262, shape=(), dtype=float32)\n",
      "INFO:tensorflow:4000 tf.Tensor(13.341753, shape=(), dtype=float32)tf.Tensor(8.624917, shape=(), dtype=float32)tf.Tensor(4.716836, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REST Non-Motif Train Time 1373.982441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:32,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:macro auROC:     0.8005522606154376\n",
      "INFO:tensorflow:auPRC:     0.09675764243203298\n",
      "INFO:tensorflow:GINI:     0.6011045771911352\n",
      "Training MAX...\n",
      "using ['K562', 'HepG2', 'HeLa-S3', 'H1', 'GM12878', 'A549'] as labels for mode Dataset.TRAIN\n",
      "using ['K562', 'HepG2', 'HeLa-S3', 'H1', 'GM12878', 'A549'] as labels for mode Dataset.VALID\n",
      "INFO:tensorflow:Starting Training\n",
      "INFO:tensorflow:0 tf.Tensor(62.72473, shape=(), dtype=float32)tf.Tensor(46.8216, shape=(), dtype=float32)tf.Tensor(15.90313, shape=(), dtype=float32)\n",
      "INFO:tensorflow:1000 tf.Tensor(21.053509, shape=(), dtype=float32)tf.Tensor(10.350472, shape=(), dtype=float32)tf.Tensor(10.703036, shape=(), dtype=float32)\n",
      "INFO:tensorflow:2000 tf.Tensor(7.6883082, shape=(), dtype=float32)tf.Tensor(0.56106055, shape=(), dtype=float32)tf.Tensor(7.127248, shape=(), dtype=float32)\n",
      "INFO:tensorflow:3000 tf.Tensor(5.913164, shape=(), dtype=float32)tf.Tensor(0.6911288, shape=(), dtype=float32)tf.Tensor(5.2220354, shape=(), dtype=float32)\n",
      "INFO:tensorflow:4000 tf.Tensor(16.13827, shape=(), dtype=float32)tf.Tensor(11.94999, shape=(), dtype=float32)tf.Tensor(4.1882796, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX Motif Train Time 1240.037551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:30,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:macro auROC:     0.827372239546872\n",
      "INFO:tensorflow:auPRC:     0.1489887172820554\n",
      "INFO:tensorflow:GINI:     0.6547444661458334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using ['K562', 'HepG2', 'HeLa-S3', 'H1', 'GM12878', 'A549'] as labels for mode Dataset.TRAIN\n",
      "using ['K562', 'HepG2', 'HeLa-S3', 'H1', 'GM12878', 'A549'] as labels for mode Dataset.VALID\n",
      "INFO:tensorflow:Starting Training\n",
      "INFO:tensorflow:0 tf.Tensor(59.076626, shape=(), dtype=float32)tf.Tensor(44.361847, shape=(), dtype=float32)tf.Tensor(14.714779, shape=(), dtype=float32)\n",
      "INFO:tensorflow:1000 tf.Tensor(11.081548, shape=(), dtype=float32)tf.Tensor(1.2275722, shape=(), dtype=float32)tf.Tensor(9.853975, shape=(), dtype=float32)\n",
      "INFO:tensorflow:2000 tf.Tensor(7.1148415, shape=(), dtype=float32)tf.Tensor(0.5644128, shape=(), dtype=float32)tf.Tensor(6.550429, shape=(), dtype=float32)\n",
      "INFO:tensorflow:3000 tf.Tensor(9.76866, shape=(), dtype=float32)tf.Tensor(4.9072995, shape=(), dtype=float32)tf.Tensor(4.86136, shape=(), dtype=float32)\n",
      "INFO:tensorflow:4000 tf.Tensor(31.569555, shape=(), dtype=float32)tf.Tensor(27.602213, shape=(), dtype=float32)tf.Tensor(3.967343, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX Non-Motif Train Time 1234.595524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:29,  5.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:macro auROC:     0.8408231506820254\n",
      "INFO:tensorflow:auPRC:     0.15878261920286174\n",
      "INFO:tensorflow:GINI:     0.6816463324390367\n",
      "Training EGR1...\n",
      "using ['K562', 'H1', 'GM12878'] as labels for mode Dataset.TRAIN\n",
      "using ['K562', 'H1', 'GM12878'] as labels for mode Dataset.VALID\n",
      "INFO:tensorflow:Starting Training\n",
      "INFO:tensorflow:0 tf.Tensor(53.79943, shape=(), dtype=float32)tf.Tensor(45.84763, shape=(), dtype=float32)tf.Tensor(7.9518027, shape=(), dtype=float32)\n",
      "INFO:tensorflow:1000 tf.Tensor(8.290697, shape=(), dtype=float32)tf.Tensor(2.5742066, shape=(), dtype=float32)tf.Tensor(5.7164907, shape=(), dtype=float32)\n",
      "INFO:tensorflow:2000 tf.Tensor(10.526819, shape=(), dtype=float32)tf.Tensor(6.291806, shape=(), dtype=float32)tf.Tensor(4.2350135, shape=(), dtype=float32)\n",
      "INFO:tensorflow:3000 tf.Tensor(3.9078176, shape=(), dtype=float32)tf.Tensor(0.47180915, shape=(), dtype=float32)tf.Tensor(3.4360085, shape=(), dtype=float32)\n",
      "INFO:tensorflow:4000 tf.Tensor(6.499288, shape=(), dtype=float32)tf.Tensor(3.4956727, shape=(), dtype=float32)tf.Tensor(3.0036154, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EGR1 Motif Train Time 830.610713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:21,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:macro auROC:     0.8680971210042676\n",
      "INFO:tensorflow:auPRC:     0.2833736567983777\n",
      "INFO:tensorflow:GINI:     0.7361942438201395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using ['K562', 'H1', 'GM12878'] as labels for mode Dataset.TRAIN\n",
      "using ['K562', 'H1', 'GM12878'] as labels for mode Dataset.VALID\n",
      "INFO:tensorflow:Starting Training\n",
      "INFO:tensorflow:0 tf.Tensor(50.697414, shape=(), dtype=float32)tf.Tensor(43.30559, shape=(), dtype=float32)tf.Tensor(7.391823, shape=(), dtype=float32)\n",
      "INFO:tensorflow:1000 tf.Tensor(24.07993, shape=(), dtype=float32)tf.Tensor(18.815435, shape=(), dtype=float32)tf.Tensor(5.264493, shape=(), dtype=float32)\n",
      "INFO:tensorflow:2000 tf.Tensor(8.728676, shape=(), dtype=float32)tf.Tensor(4.8418174, shape=(), dtype=float32)tf.Tensor(3.886859, shape=(), dtype=float32)\n",
      "INFO:tensorflow:3000 tf.Tensor(3.5481765, shape=(), dtype=float32)tf.Tensor(0.42921558, shape=(), dtype=float32)tf.Tensor(3.1189609, shape=(), dtype=float32)\n",
      "INFO:tensorflow:4000 tf.Tensor(11.482698, shape=(), dtype=float32)tf.Tensor(8.733459, shape=(), dtype=float32)tf.Tensor(2.749239, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EGR1 Non-Motif Train Time 822.888214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:21,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:macro auROC:     0.866631605601979\n",
      "INFO:tensorflow:auPRC:     0.28948371621693886\n",
      "INFO:tensorflow:GINI:     0.7332631740660701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for tf in anchor_overlap_tfs:\n",
    "    # TF's being predicted\n",
    "    TF = tf\n",
    "    \n",
    "    if TF == \"CTCF\":\n",
    "        continue\n",
    "    \n",
    "    print(\"Training %s...\" % TF)\n",
    "    query_cell = 'K562' #'T47D'\n",
    "    \n",
    "    tf_results_dir, tf_model_dir = setup_directories(TF)\n",
    "    \n",
    "    matrix, cellmap, assaymap = get_assays_from_feature_file(feature_path,\n",
    "                                                         eligible_assays = TF,\n",
    "                                                         eligible_cells = None, \n",
    "                                                         min_cells_per_assay = 2, \n",
    "                                                         min_assays_per_cell= 2)\n",
    "    \n",
    "    # Train TF with Motif Data\n",
    "    model = VLP(TF,\n",
    "            data = data,\n",
    "            matrix = matrix,\n",
    "            cellmap = cellmap,\n",
    "            assaymap = assaymap,\n",
    "            motifmat = motifmat, \n",
    "            motifmap = motifmap)\n",
    "\n",
    "    start = timer()\n",
    "    model.train(train_iterations)\n",
    "    end = timer()\n",
    "    train_time = end-start\n",
    "    print('%s Motif Train Time %f' % (TF, train_time))\n",
    "\n",
    "    model_path = os.path.join(tf_model_dir, query_cell + \"_\" + TF + \"_motif\")\n",
    "    model.save(model_path)\n",
    "    \n",
    "    # Test TF with Motif Model\n",
    "    model_results = model.test(test_iterations, calculate_metrics=True)\n",
    "#     print('%s: auROC: %s. auPRC: %s.' % (TF, model_results['auROC'], model_results['auPRC'])) \n",
    "    \n",
    "    eval_results_df = pd.DataFrame(columns=['query_cell', 'auROC', 'auPRC'])\n",
    "    eval_results_df = eval_results_df.append({ \n",
    "       'predicted_transcription_factor' : TF,\n",
    "       'query_cell' : query_cell,\n",
    "       'auROC' : model_results['auROC'],\n",
    "       'auPRC' : model_results['auPRC'],\n",
    "       'trained_transcription_factors' : TF,\n",
    "       'iterations_trained' : train_iterations,\n",
    "       'iterations_tested' : test_iterations,\n",
    "       'train_time' : train_time,\n",
    "        }, \n",
    "        ignore_index=True)\n",
    "    eval_results_df.to_csv(os.path.join(tf_results_dir, query_cell + \"_\" + TF + '_motif.csv'), \n",
    "                           sep=\"\\t\")\n",
    "\n",
    "    preds_file = os.path.join(tf_results_dir, query_cell + \"_\" + TF + '_motif.npz')\n",
    "    np.savez_compressed(preds_file ,pred=model_results['preds_mean'].numpy())\n",
    "    \n",
    "    # Train TF without Motif Data\n",
    "    model = VLP(TF,\n",
    "            data = data,\n",
    "            matrix = matrix,\n",
    "            cellmap = cellmap,\n",
    "            assaymap = assaymap)\n",
    "\n",
    "    start = timer()\n",
    "    model.train(train_iterations)\n",
    "    end = timer()\n",
    "    train_time = end-start\n",
    "    print('%s Non-Motif Train Time %f' % (TF, train_time))\n",
    "\n",
    "    model_path = os.path.join(tf_model_dir, query_cell + \"_\" + TF + \"_no_motif\")\n",
    "    model.save(model_path)\n",
    "    \n",
    "    # Test TF with Non-Motif Model\n",
    "    model_results = model.test(test_iterations, calculate_metrics=True)\n",
    "#     print('%s: auROC: %s. auPRC: %s.' % (TF, model_results['auROC'], model_results['auPRC'])) \n",
    "    \n",
    "    eval_results_df = pd.DataFrame(columns=['query_cell', 'auROC', 'auPRC'])\n",
    "    eval_results_df = eval_results_df.append({ \n",
    "       'predicted_transcription_factor' : TF,\n",
    "       'query_cell' : query_cell,\n",
    "       'auROC' : model_results['auROC'],\n",
    "       'auPRC' : model_results['auPRC'],\n",
    "       'trained_transcription_factors' : TF,\n",
    "       'iterations_trained' : train_iterations,\n",
    "       'iterations_tested' : test_iterations,\n",
    "       'train_time' : train_time,\n",
    "        }, \n",
    "        ignore_index=True)\n",
    "    eval_results_df.to_csv(os.path.join(tf_results_dir, query_cell + \"_\" + TF + '_no_motif.csv'), \n",
    "                           sep=\"\\t\")\n",
    "\n",
    "    preds_file = os.path.join(tf_results_dir, query_cell + \"_\" + TF + '_no_motif.npz')\n",
    "    np.savez_compressed(preds_file ,pred=model_results['preds_mean'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EpitomeNewEnv2",
   "language": "python",
   "name": "epitomenewenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
